{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This report contains the main steps involved in the data-wrangling of Twitter account\n",
    "”WeRate- Doges”.\n",
    "### Data Gathering\n",
    " In this step,I collected data from three sources :\n",
    "- Twitter_archive_enhanced.csv file, this file downloaded manually to my working directory.\n",
    " Then imported into working environment using pandas function “pd.read.csv”.\n",
    "- Image_prediction.tsv is the second file, it hosted from webpage and downloaded it from its\n",
    "relevant URL using Requests library get function and pd.read.csv pandas function. This file\n",
    "is containing image predictions for the dogs breeds obtained through a neural network on\n",
    "most of the tweets in the archive file.\n",
    "- The third dataset was gathered form twitter REST API via the tweepy library by querying the\n",
    "API to obtain extra information pertinent to the tweets’ ids in twitter_archive_enhanced.csv\n",
    "file, e.g. retweets count and favorite count .\n",
    "\n",
    "### Data assessment\n",
    "in this step, I investigate the datasets both visually and programmatically for quality and tidiness\n",
    "issues.\n",
    "- I do the visual assessment on excel spreadsheet. Then, the programmatic assessment is\n",
    "   donein Jupyter notebook.\n",
    "- First I addressed the missing values. Then addressed the tidiness issues second to facilitate\n",
    "  the tackling of the rest of quality issues that were validity, accuracy and consistency classes\n",
    "  forthe quality aspects and extracts these assessment point :\n",
    "#### Quality aspects:\n",
    "archive table\n",
    "- retweets and replies not requird (’in_reply_to_status_id’,’in_reply_to_user_id’,’retweeted_status_id’,\n",
    "  ’retweeted_status_user_id’, ’retweeted_status_timestamp’)\n",
    "- some expanded_urls doesn’t have pictures\n",
    "- missing values in name, doggo,floofer,pupper,puppo\n",
    "- rating_numerator have values greater than 15 and smaller than 6 and some contain decimals\n",
    "- rating_demoniator have values not equal 10\n",
    "- Erroneous datatypes (timestamp, tweet_id)\n",
    "- weird names in name column\n",
    "image_prediction table\n",
    "- Erroneous datatypes (tweet_id)\n",
    "- there’re tweets_id not have image\n",
    "api table\n",
    "- Erroneous datatypes (tweet_id)\n",
    "#### Tidiness aspects:\n",
    "- one column for doggo and floffer, pupper and puppo\n",
    "- columns headers are values not varibale name in image prediction\n",
    "- Api table isn’t an observational unit to have its own table\n",
    "### Data Cleaning\n",
    "first make a copy from original tables\n",
    "#### Quality issues\n",
    "archive table\n",
    "- change timestamp type from string to date using astype(’datetime64’)\n",
    "- change tweet_id type from int to string using astype(’str’)\n",
    "- Removed the rows that have no expanded_url entry\n",
    "- fixing rating_numerator values that greater than 15 and smaller than 6 by slice their tweets\n",
    "  and investigate texts and extract their values from texts\n",
    "- changing all inconsistent value such as a, an and any name less than 3 letters in name column\n",
    "  image prediction table\n",
    "- changing datetype of tweet_id from int to str in image prediction table\n",
    "  API table\n",
    "- changing datetype of tweet_id from int to str in API table\n",
    "### Tidiness issues\n",
    "- combine four dog stages into one column dog_stage and drop doggo,floofer,pupper,puppo\n",
    "  columns where :\n",
    "at first assigned the last four columns of the archive dataframe to its new value records\n",
    "without None and Getting all the tweets where the value of both ’doggo’ and ’pupper’ is\n",
    "not none, Extracted only those the columns of interest and investigate its head. and com-\n",
    "bined 4 dog stages using addition operation. then,replaced empty string with np.nan. after\n",
    "that,separated the combined stages with a hyphen then dropped dogs type cloumns and\n",
    "tested this step using ’info()’ to confirm that all columns combined well.\n",
    "- drop records not have images then drop replies and retweets and drop retweets and replies\n",
    "from image table :\n",
    "at first create a list of tweet_ids with images \"tweets_with_image\" and confirming that all\n",
    "the tweets with images exist in the archive dataset length. then, extracted the retweets that\n",
    "include data in the retweet_status_id. and dropped the retweets from the archive data set.\n",
    "and Extracted replies entries that include data. then checked image_prediction table for\n",
    "extra tweet ids not in archive table after that,dropped retweets and replies ids from image\n",
    "prediction dataframe and tested this issues using ’shape’ method for archive table and image\n",
    "table and I confirmed that the two tables are identical rows.\n",
    "- reshaping image_prediction cloumn using pd.wide_to_long to do that first edit the name of\n",
    "columns in image_prediction table\n",
    "at first renamed the dataset columns with clear names, then reshaping the dataframe us-\n",
    "ing’pd.wide_to_long’\n",
    "- merage api table and archive table together\n",
    "in this step I meraged api and archive tables using left join to keep all tweets id in archive\n",
    "table\n",
    "- delete retweets and replies from table\n",
    "I deleted retweets and replies from dataframe\n",
    "### Output:\n",
    "two tables :\n",
    "- twitter_archive_master table 1981 record\n",
    "- prediction table 5943 entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
